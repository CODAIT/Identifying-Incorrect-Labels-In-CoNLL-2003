{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hand token relabelling script\n",
    "\n",
    "Because of (a) the non-standard nature of token corrections and (b) the relatively few number of them avaliable, we used a hand re-annotation process to identify the changes needing to be made to each line of interest. This Notebook provides a basic user interface to carry out that process, and saves the outputs to a csv file which then can be used to re-label the corpus. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import fileinput\n",
    "import sys\n",
    "import glob \n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "filenames = {\"test\":  '../original_corpus/eng.testb',\n",
    "             \"dev\" :  '../original_corpus/eng.testa',\n",
    "             \"train\": '../original_corpus/eng.train'}\n",
    "folds = ['test','dev','train']\n",
    "dtypes_in = {'correct_line':str}\n",
    "\n",
    "log = []\n",
    "log.append(\"line, num_added\")\n",
    "\n",
    "files = {}\n",
    "for fold,filename in filenames.items(): \n",
    "    print(fold,filename)\n",
    "    with open(filename, 'r') as file:\n",
    "        files[fold] = file.readlines()\n",
    "\n",
    "filenames\n",
    "#read dataframe from file\n",
    "corrections = pd.read_csv(\"../corrected_labels/token_edits.csv\",dtype = dtypes_in)\n",
    "corrections = corrections[['fold','line_no','doc_offset','corpus_span','correct_span','correct_line']]\n",
    "corrections.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " \n",
    "def print_with_numbering(file, s, e):\n",
    "        for i in range(s,e):\n",
    "            print(i, file[i])\n",
    "        \n",
    "def show_lines(line, file, line_end = None):\n",
    "    line_end = line +2 if (line_end== None) else line_end\n",
    "    print_with_numbering(file,line-1,line_end+1 )\n",
    "\n",
    "def get_corpus_line(line):\n",
    "    return data[line]\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run this to reset count\n",
    "curr_row = 0; \n",
    "fold = \"dev\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for now just display\n",
    "# when this bool is set to true, replace line with given text\n",
    "prompt_for_correct = True;\n",
    "\n",
    "for _,row in (corrections.loc[curr_row:curr_row+2]).iterrows():\n",
    "    print(row.to_list())\n",
    "    show_lines(row.line_no, files[row.fold])\n",
    "        \n",
    "if(prompt_for_correct):\n",
    "    print(\"enter correct input for first entry\")\n",
    "    inp = input()\n",
    "    if(inp == 'delete_entry'):\n",
    "        corrections.drop(index=curr_row,axis = 1);\n",
    "    else: \n",
    "        inp = inp.replace(\"\\\\n\",\"\\n\")\n",
    "        corrections.at[curr_row,'correct_line'] = inp\n",
    "        print(\"\\n line gotten: \\n\")\n",
    "        print(inp)\n",
    "\n",
    "curr_row += 1 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# curr_row -=1\n",
    "display(curr_row)\n",
    "corrections.head(curr_row).tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sometimes two errors in the labels were created by a single token error - one for the object in front of the error and one for the object after it. \n",
    "# we want to remove these duplicates for the final processing. \n",
    "# also remove non-filled out lines. \n",
    "corrections_preened = corrections.drop_duplicates([\"fold\",\"line_no\", \"doc_offset\"], ignore_index=True); \n",
    "corrections_preened = corrections_preened[corrections_preened[\"correct_line\"] != '']\n",
    "corrections_preened.set_index(\"line_no\", inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"../corrected_labels/token_corrections.json\",'w') as file:\n",
    "    corrections_preened.to_json(file)\n",
    "print(\"printed to file\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
