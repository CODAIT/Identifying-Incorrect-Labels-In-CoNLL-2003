{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import glob\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "sys.path.append(os.path.abspath('../../text-extensions-for-pandas'))\n",
    "import text_extensions_for_pandas as tp\n",
    "\n",
    "from correct_label_errors import Dataset\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "files = {\n",
    "    'csv_files' : [\"../corrected_labels/all_conll_corrections_combined.csv\"],\n",
    "    'dev'       : \"../original_corpus/eng.testa\",\n",
    "    'test'      : \"../original_corpus/eng.testb\",\n",
    "    'train'     : \"../original_corpus/eng.train\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>doc_offset</th>\n",
       "      <th>corpus_span</th>\n",
       "      <th>correct_span</th>\n",
       "      <th>error_type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>80.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[44, 59): 'Interfax'</td>\n",
       "      <td>Token</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>80.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[51, 59): 'Interfax'</td>\n",
       "      <td>Token</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>115.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[23, 27): 'News'</td>\n",
       "      <td>Token</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>163.0</td>\n",
       "      <td>[220, 232): 'x-AEK Athens'</td>\n",
       "      <td>[222, 232): 'AEK Athens'</td>\n",
       "      <td>Token</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>163.0</td>\n",
       "      <td>[271, 283): 'x-Olympiakos'</td>\n",
       "      <td>[273, 283): 'Olympiakos'</td>\n",
       "      <td>Token</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>163.0</td>\n",
       "      <td>[308, 313): 'x-PAO'</td>\n",
       "      <td>[310, 313): 'PAO'</td>\n",
       "      <td>Token</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>169.0</td>\n",
       "      <td>[50, 61): 'trip-Canada'</td>\n",
       "      <td>[55, 61): 'Canada'</td>\n",
       "      <td>Token</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>298.0</td>\n",
       "      <td>[49, 60): '1997--Ruehe'</td>\n",
       "      <td>[55, 60): 'Ruehe'</td>\n",
       "      <td>Token</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>343.0</td>\n",
       "      <td>[11, 31): 'AUSTRALIAN RULES-AFL'</td>\n",
       "      <td>[11, 21): 'AUSTRALIAN'</td>\n",
       "      <td>Token</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>343.0</td>\n",
       "      <td>[11, 31): 'AUSTRALIAN RULES-AFL'</td>\n",
       "      <td>[11, 27): 'AUSTRALIAN RULES'</td>\n",
       "      <td>Token</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>343.0</td>\n",
       "      <td>[11, 31): 'AUSTRALIAN RULES-AFL'</td>\n",
       "      <td>[28, 31): 'AFL'</td>\n",
       "      <td>Token</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>343.0</td>\n",
       "      <td>[11, 31): 'AUSTRALIAN RULES-AFL'</td>\n",
       "      <td>[11, 21): 'AUSTRALIAN'</td>\n",
       "      <td>Token</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>422.0</td>\n",
       "      <td>[236, 246): 'Videoton(*'</td>\n",
       "      <td>[236, 244): 'Videoton'</td>\n",
       "      <td>Token</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>593.0</td>\n",
       "      <td>[45, 57): 'France-Juppe'</td>\n",
       "      <td>[45, 51): 'France'</td>\n",
       "      <td>Token</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>593.0</td>\n",
       "      <td>[45, 57): 'France-Juppe'</td>\n",
       "      <td>[52, 57): 'Juppe'</td>\n",
       "      <td>Token</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>626.0</td>\n",
       "      <td>[42, 59): 'disarmament-China'</td>\n",
       "      <td>[42, 59): 'disarmament-China'</td>\n",
       "      <td>Token</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>701.0</td>\n",
       "      <td>[17, 30): 'union-England'</td>\n",
       "      <td>[23, 30): 'England'</td>\n",
       "      <td>Token</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>918.0</td>\n",
       "      <td>[11, 24): 'INTERVIEW-T&amp;N'</td>\n",
       "      <td>[11, 24): 'INTERVIEW-T&amp;N'</td>\n",
       "      <td>Token</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>918.0</td>\n",
       "      <td>[11, 24): 'INTERVIEW-T&amp;N'</td>\n",
       "      <td>[21, 24): 'T&amp;N'</td>\n",
       "      <td>Token</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    doc_offset                       corpus_span  \\\n",
       "0         80.0                               NaN   \n",
       "1         80.0                               NaN   \n",
       "2        115.0                               NaN   \n",
       "3        163.0        [220, 232): 'x-AEK Athens'   \n",
       "4        163.0        [271, 283): 'x-Olympiakos'   \n",
       "5        163.0               [308, 313): 'x-PAO'   \n",
       "6        169.0           [50, 61): 'trip-Canada'   \n",
       "7        298.0           [49, 60): '1997--Ruehe'   \n",
       "8        343.0  [11, 31): 'AUSTRALIAN RULES-AFL'   \n",
       "9        343.0  [11, 31): 'AUSTRALIAN RULES-AFL'   \n",
       "10       343.0  [11, 31): 'AUSTRALIAN RULES-AFL'   \n",
       "11       343.0  [11, 31): 'AUSTRALIAN RULES-AFL'   \n",
       "12       422.0          [236, 246): 'Videoton(*'   \n",
       "13       593.0          [45, 57): 'France-Juppe'   \n",
       "14       593.0          [45, 57): 'France-Juppe'   \n",
       "15       626.0     [42, 59): 'disarmament-China'   \n",
       "16       701.0         [17, 30): 'union-England'   \n",
       "17       918.0         [11, 24): 'INTERVIEW-T&N'   \n",
       "18       918.0         [11, 24): 'INTERVIEW-T&N'   \n",
       "\n",
       "                     correct_span error_type  \n",
       "0            [44, 59): 'Interfax'      Token  \n",
       "1            [51, 59): 'Interfax'      Token  \n",
       "2                [23, 27): 'News'      Token  \n",
       "3        [222, 232): 'AEK Athens'      Token  \n",
       "4        [273, 283): 'Olympiakos'      Token  \n",
       "5               [310, 313): 'PAO'      Token  \n",
       "6              [55, 61): 'Canada'      Token  \n",
       "7               [55, 60): 'Ruehe'      Token  \n",
       "8          [11, 21): 'AUSTRALIAN'      Token  \n",
       "9    [11, 27): 'AUSTRALIAN RULES'      Token  \n",
       "10                [28, 31): 'AFL'      Token  \n",
       "11         [11, 21): 'AUSTRALIAN'      Token  \n",
       "12         [236, 244): 'Videoton'      Token  \n",
       "13             [45, 51): 'France'      Token  \n",
       "14              [52, 57): 'Juppe'      Token  \n",
       "15  [42, 59): 'disarmament-China'      Token  \n",
       "16            [23, 30): 'England'      Token  \n",
       "17      [11, 24): 'INTERVIEW-T&N'      Token  \n",
       "18                [21, 24): 'T&N'      Token  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>doc_offset</th>\n",
       "      <th>corpus_span</th>\n",
       "      <th>correct_span</th>\n",
       "      <th>error_type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>15.0</td>\n",
       "      <td>[41, 51): 'CUNNINGHAM'</td>\n",
       "      <td>(33, 51]: 'RANDALL CUNNINGHAM'</td>\n",
       "      <td>Token</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>15.0</td>\n",
       "      <td>[41, 51): 'CUNNINGHAM'</td>\n",
       "      <td>(33,51] 'RANDALL CUNNINGHAM'</td>\n",
       "      <td>Token</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>15.0</td>\n",
       "      <td>[15, 40): 'AMERICAN FOOTBALL-RANDALL'</td>\n",
       "      <td>[15, 32): 'AMERICAN FOOTBALL'</td>\n",
       "      <td>Token</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>15.0</td>\n",
       "      <td>[15, 40): 'AMERICAN FOOTBALL-RANDALL'</td>\n",
       "      <td>[33, 40): 'RANDALL'</td>\n",
       "      <td>Token</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>15.0</td>\n",
       "      <td>[41, 51): 'CUNNINGHAM'</td>\n",
       "      <td>[33,51): 'RANDALL CUNNINGHAM'</td>\n",
       "      <td>Token</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>39.0</td>\n",
       "      <td>[11, 23): 'Boxing-Bruno'</td>\n",
       "      <td>[18, 23): 'Bruno'</td>\n",
       "      <td>Token</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>39.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[18, 23): 'Bruno'\\t</td>\n",
       "      <td>Token</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>60.0</td>\n",
       "      <td>[1358, 1371): 'Tripoli-based'</td>\n",
       "      <td>[1358, 1365): 'Tripoli'</td>\n",
       "      <td>Token</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>65.0</td>\n",
       "      <td>[1125, 1134): 'asset-St.'</td>\n",
       "      <td>[1131, 1146): 'St. Louis based'</td>\n",
       "      <td>Token</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>65.0</td>\n",
       "      <td>[592, 607): 'St. Louis-based'</td>\n",
       "      <td>[592, 601): 'St. Louis'</td>\n",
       "      <td>Token</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>65.0</td>\n",
       "      <td>[1125, 1134): 'asset-St.'</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Token</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>175.0</td>\n",
       "      <td>[252, 264): 'London-based'</td>\n",
       "      <td>[252, 258): 'London'</td>\n",
       "      <td>Token</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>181.0</td>\n",
       "      <td>[1761, 1774): 'Moscow-backed'</td>\n",
       "      <td>[1761, 1767): 'Moscow'</td>\n",
       "      <td>Token</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>198.0</td>\n",
       "      <td>[39, 47): 'aid-U.N.'</td>\n",
       "      <td>[43, 47): 'U.N.'</td>\n",
       "      <td>Token</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    doc_offset                            corpus_span  \\\n",
       "0         15.0                 [41, 51): 'CUNNINGHAM'   \n",
       "1         15.0                 [41, 51): 'CUNNINGHAM'   \n",
       "2         15.0  [15, 40): 'AMERICAN FOOTBALL-RANDALL'   \n",
       "3         15.0  [15, 40): 'AMERICAN FOOTBALL-RANDALL'   \n",
       "4         15.0                 [41, 51): 'CUNNINGHAM'   \n",
       "5         39.0               [11, 23): 'Boxing-Bruno'   \n",
       "6         39.0                                    NaN   \n",
       "7         60.0          [1358, 1371): 'Tripoli-based'   \n",
       "8         65.0              [1125, 1134): 'asset-St.'   \n",
       "9         65.0          [592, 607): 'St. Louis-based'   \n",
       "10        65.0              [1125, 1134): 'asset-St.'   \n",
       "11       175.0             [252, 264): 'London-based'   \n",
       "12       181.0          [1761, 1774): 'Moscow-backed'   \n",
       "13       198.0                   [39, 47): 'aid-U.N.'   \n",
       "\n",
       "                       correct_span error_type  \n",
       "0    (33, 51]: 'RANDALL CUNNINGHAM'      Token  \n",
       "1      (33,51] 'RANDALL CUNNINGHAM'      Token  \n",
       "2     [15, 32): 'AMERICAN FOOTBALL'      Token  \n",
       "3               [33, 40): 'RANDALL'      Token  \n",
       "4     [33,51): 'RANDALL CUNNINGHAM'      Token  \n",
       "5                 [18, 23): 'Bruno'      Token  \n",
       "6               [18, 23): 'Bruno'\\t      Token  \n",
       "7           [1358, 1365): 'Tripoli'      Token  \n",
       "8   [1131, 1146): 'St. Louis based'      Token  \n",
       "9           [592, 601): 'St. Louis'      Token  \n",
       "10                              NaN      Token  \n",
       "11             [252, 258): 'London'      Token  \n",
       "12           [1761, 1767): 'Moscow'      Token  \n",
       "13                 [43, 47): 'U.N.'      Token  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>doc_offset</th>\n",
       "      <th>corpus_span</th>\n",
       "      <th>correct_span</th>\n",
       "      <th>error_type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3.0</td>\n",
       "      <td>[21, 37): 'SKIING-WORLD CUP'</td>\n",
       "      <td>[28, 37): 'WORLD CUP'</td>\n",
       "      <td>Token</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3.0</td>\n",
       "      <td>[21, 37): 'SKIING-WORLD CUP'</td>\n",
       "      <td>[28,37)'WORLD CUP'</td>\n",
       "      <td>Token</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>22.0</td>\n",
       "      <td>[19, 23): 'ARAB'</td>\n",
       "      <td>[19, 35): 'ARAB CONTRACTORS'</td>\n",
       "      <td>Token</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>27.0</td>\n",
       "      <td>[565, 573): 'X-DENVER'</td>\n",
       "      <td>[567, 573): 'DENVER'</td>\n",
       "      <td>Token</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>27.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[567, 573): 'DENVER'</td>\n",
       "      <td>Token</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>27.0</td>\n",
       "      <td>[889, 900): 'Y-GREEN BAY'</td>\n",
       "      <td>[891, 900): 'GREEN BAY'</td>\n",
       "      <td>Token</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>29.0</td>\n",
       "      <td>[25, 44): 'FOOTBALL-OHIO STATE'</td>\n",
       "      <td>[34, 44): 'OHIO STATE'</td>\n",
       "      <td>Token</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>29.0</td>\n",
       "      <td>[25, 44): 'FOOTBALL-OHIO STATE'</td>\n",
       "      <td>[34,44): 'OHIO STATE'</td>\n",
       "      <td>Token</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>39.0</td>\n",
       "      <td>[1158, 1175): 'AbelardoFernandez'</td>\n",
       "      <td>[1158, 1175): 'Abelardo Fernandez'</td>\n",
       "      <td>Token</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>54.0</td>\n",
       "      <td>[1145, 1152): 'Boxmeer'</td>\n",
       "      <td>[1141, 1152): 'van Boxmeer'</td>\n",
       "      <td>Token</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>54.0</td>\n",
       "      <td>[11, 27): 'INTERVIEW-ZYWIEC'</td>\n",
       "      <td>[21, 27): 'ZYWIEC'</td>\n",
       "      <td>Token</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>54.0</td>\n",
       "      <td>[2594, 2601): 'Boxmeer'</td>\n",
       "      <td>[2590, 2601): 'van Boxmeer'</td>\n",
       "      <td>Token</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>54.0</td>\n",
       "      <td>[3231, 3241): 'Full Light'</td>\n",
       "      <td>[3224, 3241): 'Zywiec Full Light'</td>\n",
       "      <td>Token</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>54.0</td>\n",
       "      <td>[3421, 3428): 'Boxmeer'</td>\n",
       "      <td>[3417, 3428): 'van Boxmeer'</td>\n",
       "      <td>Token</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>54.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[?, 27): 'ZYWIEC'</td>\n",
       "      <td>Token</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>56.0</td>\n",
       "      <td>[11, 16): 'UK-US'</td>\n",
       "      <td>[11, 13): 'UK'</td>\n",
       "      <td>Token</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>56.0</td>\n",
       "      <td>[11, 16): 'UK-US'</td>\n",
       "      <td>[11,13) 'UK'</td>\n",
       "      <td>Token</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>56.0</td>\n",
       "      <td>[11, 16): 'UK-US'</td>\n",
       "      <td>[14, 16): 'US'</td>\n",
       "      <td>Token</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>56.0</td>\n",
       "      <td>[11, 16): 'UK-US'</td>\n",
       "      <td>[14,16) 'UK'</td>\n",
       "      <td>Token</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>60.0</td>\n",
       "      <td>[345, 363): 'Trade and Industry'</td>\n",
       "      <td>[345, 373): 'Trade and Industry Secretary'</td>\n",
       "      <td>Token</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>63.0</td>\n",
       "      <td>[19, 39): 'office-Conservatives'</td>\n",
       "      <td>[26, 39): 'Conservatives'</td>\n",
       "      <td>Token</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>63.0</td>\n",
       "      <td>[19, 39): 'office-Conservatives'</td>\n",
       "      <td>[27, 39): 'Conservatives'</td>\n",
       "      <td>Token</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>68.0</td>\n",
       "      <td>[11, 19): 'Canadian'</td>\n",
       "      <td>[11, 30): 'Canadian West Coast'</td>\n",
       "      <td>Token</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>68.0</td>\n",
       "      <td>[157, 165): 'Canadian'</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Token</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>70.0</td>\n",
       "      <td>[177, 197): 'New York Commodities'</td>\n",
       "      <td>[177, 202): 'New York Commodities Desk'</td>\n",
       "      <td>Token</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>71.0</td>\n",
       "      <td>[153, 173): 'New York Commodities'</td>\n",
       "      <td>[153, 178): 'New York Commodities Desk'</td>\n",
       "      <td>Token</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>75.0</td>\n",
       "      <td>[2736, 2752): 'Newmont-Santa Fe'</td>\n",
       "      <td>[2736, 2743): 'Newmont'</td>\n",
       "      <td>Token</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>75.0</td>\n",
       "      <td>[2736, 2752): 'Newmont-Santa Fe'</td>\n",
       "      <td>[2744, 2752): 'Santa Fe'</td>\n",
       "      <td>Token</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>114.0</td>\n",
       "      <td>[11, 17): 'Iowa-S'</td>\n",
       "      <td>[11, 15): 'Iowa'</td>\n",
       "      <td>Token</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>114.0</td>\n",
       "      <td>[11, 17): 'Iowa-S'</td>\n",
       "      <td>[11, 15): 'Iowa'</td>\n",
       "      <td>Token</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>114.0</td>\n",
       "      <td>[51, 61): 'sales-USDA'</td>\n",
       "      <td>[57, 61): 'USDA'</td>\n",
       "      <td>Token</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>114.0</td>\n",
       "      <td>[51, 61): 'sales-USDA'</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Token</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>123.0</td>\n",
       "      <td>[11, 17): 'Iowa-S'</td>\n",
       "      <td>[11, 15): 'Iowa'</td>\n",
       "      <td>Token</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>178.0</td>\n",
       "      <td>[951, 960): 'then-U.S.'</td>\n",
       "      <td>[956, 960): 'U.S.'</td>\n",
       "      <td>Token</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>183.0</td>\n",
       "      <td>[18, 35): 'SKIING-GLADISHIVA'</td>\n",
       "      <td>[25, 35): 'GLADISHIVA'</td>\n",
       "      <td>Token</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>186.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[1398, 1405): 'Austria'</td>\n",
       "      <td>Token</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>188.0</td>\n",
       "      <td>[18, 34): 'SKIING-WORLD CUP'</td>\n",
       "      <td>[25, 34): 'WORLD CUP'</td>\n",
       "      <td>Token</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>190.0</td>\n",
       "      <td>[11, 27): 'BOBSLEIGH-SHIMER'</td>\n",
       "      <td>[21, 27): 'SHIMER'</td>\n",
       "      <td>Token</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>190.0</td>\n",
       "      <td>[11, 27): 'BOBSLEIGH-SHIMER'</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Token</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>191.0</td>\n",
       "      <td>[11, 25): 'SKIING-CHINESE'</td>\n",
       "      <td>[18, 25): 'CHINESE'</td>\n",
       "      <td>Token</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>192.0</td>\n",
       "      <td>[11, 30): 'BOBSLEIGH-WORLD CUP'</td>\n",
       "      <td>[21, 30): 'WORLD CUP'</td>\n",
       "      <td>Token</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>194.0</td>\n",
       "      <td>[21, 37): 'SKIING-WORLD CUP'</td>\n",
       "      <td>[28, 37): 'WORLD CUP'</td>\n",
       "      <td>Token</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>195.0</td>\n",
       "      <td>[21, 37): 'SKIING-WORLD CUP'</td>\n",
       "      <td>[28, 37): 'WORLD CUP'</td>\n",
       "      <td>Token</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>214.0</td>\n",
       "      <td>[243, 262): 'Saturday'sWorld Cup'</td>\n",
       "      <td>[253, 262): 'World Cup'</td>\n",
       "      <td>Token</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    doc_offset                         corpus_span  \\\n",
       "0          3.0        [21, 37): 'SKIING-WORLD CUP'   \n",
       "1          3.0        [21, 37): 'SKIING-WORLD CUP'   \n",
       "2         22.0                    [19, 23): 'ARAB'   \n",
       "3         27.0              [565, 573): 'X-DENVER'   \n",
       "4         27.0                                 NaN   \n",
       "5         27.0           [889, 900): 'Y-GREEN BAY'   \n",
       "6         29.0     [25, 44): 'FOOTBALL-OHIO STATE'   \n",
       "7         29.0     [25, 44): 'FOOTBALL-OHIO STATE'   \n",
       "8         39.0   [1158, 1175): 'AbelardoFernandez'   \n",
       "9         54.0             [1145, 1152): 'Boxmeer'   \n",
       "10        54.0        [11, 27): 'INTERVIEW-ZYWIEC'   \n",
       "11        54.0             [2594, 2601): 'Boxmeer'   \n",
       "12        54.0          [3231, 3241): 'Full Light'   \n",
       "13        54.0             [3421, 3428): 'Boxmeer'   \n",
       "14        54.0                                 NaN   \n",
       "15        56.0                   [11, 16): 'UK-US'   \n",
       "16        56.0                   [11, 16): 'UK-US'   \n",
       "17        56.0                   [11, 16): 'UK-US'   \n",
       "18        56.0                   [11, 16): 'UK-US'   \n",
       "19        60.0    [345, 363): 'Trade and Industry'   \n",
       "20        63.0    [19, 39): 'office-Conservatives'   \n",
       "21        63.0    [19, 39): 'office-Conservatives'   \n",
       "22        68.0                [11, 19): 'Canadian'   \n",
       "23        68.0              [157, 165): 'Canadian'   \n",
       "24        70.0  [177, 197): 'New York Commodities'   \n",
       "25        71.0  [153, 173): 'New York Commodities'   \n",
       "26        75.0    [2736, 2752): 'Newmont-Santa Fe'   \n",
       "27        75.0    [2736, 2752): 'Newmont-Santa Fe'   \n",
       "28       114.0                  [11, 17): 'Iowa-S'   \n",
       "29       114.0                  [11, 17): 'Iowa-S'   \n",
       "30       114.0              [51, 61): 'sales-USDA'   \n",
       "31       114.0              [51, 61): 'sales-USDA'   \n",
       "32       123.0                  [11, 17): 'Iowa-S'   \n",
       "33       178.0             [951, 960): 'then-U.S.'   \n",
       "34       183.0       [18, 35): 'SKIING-GLADISHIVA'   \n",
       "35       186.0                                 NaN   \n",
       "36       188.0        [18, 34): 'SKIING-WORLD CUP'   \n",
       "37       190.0        [11, 27): 'BOBSLEIGH-SHIMER'   \n",
       "38       190.0        [11, 27): 'BOBSLEIGH-SHIMER'   \n",
       "39       191.0          [11, 25): 'SKIING-CHINESE'   \n",
       "40       192.0     [11, 30): 'BOBSLEIGH-WORLD CUP'   \n",
       "41       194.0        [21, 37): 'SKIING-WORLD CUP'   \n",
       "42       195.0        [21, 37): 'SKIING-WORLD CUP'   \n",
       "43       214.0   [243, 262): 'Saturday'sWorld Cup'   \n",
       "\n",
       "                                  correct_span error_type  \n",
       "0                        [28, 37): 'WORLD CUP'      Token  \n",
       "1                           [28,37)'WORLD CUP'      Token  \n",
       "2                 [19, 35): 'ARAB CONTRACTORS'      Token  \n",
       "3                         [567, 573): 'DENVER'      Token  \n",
       "4                         [567, 573): 'DENVER'      Token  \n",
       "5                      [891, 900): 'GREEN BAY'      Token  \n",
       "6                       [34, 44): 'OHIO STATE'      Token  \n",
       "7                        [34,44): 'OHIO STATE'      Token  \n",
       "8           [1158, 1175): 'Abelardo Fernandez'      Token  \n",
       "9                  [1141, 1152): 'van Boxmeer'      Token  \n",
       "10                          [21, 27): 'ZYWIEC'      Token  \n",
       "11                 [2590, 2601): 'van Boxmeer'      Token  \n",
       "12           [3224, 3241): 'Zywiec Full Light'      Token  \n",
       "13                 [3417, 3428): 'van Boxmeer'      Token  \n",
       "14                           [?, 27): 'ZYWIEC'      Token  \n",
       "15                              [11, 13): 'UK'      Token  \n",
       "16                                [11,13) 'UK'      Token  \n",
       "17                              [14, 16): 'US'      Token  \n",
       "18                                [14,16) 'UK'      Token  \n",
       "19  [345, 373): 'Trade and Industry Secretary'      Token  \n",
       "20                 [26, 39): 'Conservatives'        Token  \n",
       "21                   [27, 39): 'Conservatives'      Token  \n",
       "22             [11, 30): 'Canadian West Coast'      Token  \n",
       "23                                         NaN      Token  \n",
       "24     [177, 202): 'New York Commodities Desk'      Token  \n",
       "25     [153, 178): 'New York Commodities Desk'      Token  \n",
       "26                     [2736, 2743): 'Newmont'      Token  \n",
       "27                    [2744, 2752): 'Santa Fe'      Token  \n",
       "28                            [11, 15): 'Iowa'      Token  \n",
       "29                          [11, 15): 'Iowa'        Token  \n",
       "30                            [57, 61): 'USDA'      Token  \n",
       "31                                         NaN      Token  \n",
       "32                          [11, 15): 'Iowa'        Token  \n",
       "33                          [956, 960): 'U.S.'      Token  \n",
       "34                      [25, 35): 'GLADISHIVA'      Token  \n",
       "35                     [1398, 1405): 'Austria'      Token  \n",
       "36                       [25, 34): 'WORLD CUP'      Token  \n",
       "37                          [21, 27): 'SHIMER'      Token  \n",
       "38                                         NaN      Token  \n",
       "39                         [18, 25): 'CHINESE'      Token  \n",
       "40                       [21, 30): 'WORLD CUP'      Token  \n",
       "41                       [28, 37): 'WORLD CUP'      Token  \n",
       "42                       [28, 37): 'WORLD CUP'      Token  \n",
       "43                     [253, 262): 'World Cup'      Token  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "columns = ['doc_offset', 'corpus_span', 'correct_span', 'error_type']\n",
    "\n",
    "test_df = pd.DataFrame(columns = columns)\n",
    "dev_df = pd.DataFrame(columns = columns)\n",
    "train_df = pd.DataFrame(columns = columns)\n",
    "\n",
    "for f in files['csv_files']:\n",
    "    current_df = pd.read_csv(os.path.abspath(f))\n",
    "    test_df = test_df.append(current_df[(current_df[\"error_type\"]==\"Token\") & (current_df[\"fold\"]==\"test\")][columns], ignore_index=True)\n",
    "    dev_df = dev_df.append(current_df[(current_df[\"error_type\"]==\"Token\") & (current_df[\"fold\"]==\"dev\")][columns], ignore_index=True)\n",
    "    train_df = train_df.append(current_df[(current_df[\"error_type\"]==\"Token\") & (current_df[\"fold\"]==\"train\")][columns], ignore_index=True)\n",
    "    \n",
    "display(train_df)\n",
    "display(dev_df)\n",
    "display(test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df.to_csv(\"../corrected_labels/token_corection_test.csv\")\n",
    "dev_df.to_csv(\"../corrected_labels/token_corection_dev.csv\")\n",
    "train_df.to_csv(\"../corrected_labels/token_corection_train.csv\")\n",
    "correction_df = {\n",
    "    'dev'  : dev_df,\n",
    "    'test' : test_df,\n",
    "    'train': train_df\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4120\n",
      "4120\n",
      "4118\n",
      "4118\n",
      "4120\n",
      "10619\n",
      "The correct_span did not match lines. dev, 6\n",
      "-2\n",
      "15911\n",
      "19233\n",
      "19130\n",
      "19233\n",
      "44837\n",
      "46457\n",
      "50964\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[WARNING] Could not find [18, 23): 'Bruno'\t\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1131\n",
      "1131\n",
      "5174\n",
      "6545\n",
      "The correct_span did not match lines. test, 4\n",
      "-2\n",
      "6640\n",
      "6851\n",
      "6851\n",
      "8644\n",
      "12284\n",
      "12068\n",
      "12555\n",
      "12682\n",
      "12720\n",
      "The correct_span did not match lines. test, 14\n",
      "-2\n",
      "13001\n",
      "13001\n",
      "13001\n",
      "13001\n",
      "13447\n",
      "14467\n",
      "14467\n",
      "15155\n",
      "15183\n",
      "15337\n",
      "15380\n",
      "16319\n",
      "16319\n",
      "26720\n",
      "26720\n",
      "26728\n",
      "26728\n",
      "28718\n",
      "38688\n",
      "39979\n",
      "The correct_span did not match lines. test, 35\n",
      "-2\n",
      "41169\n",
      "41413\n",
      "41413\n",
      "41595\n",
      "41850\n",
      "42385\n",
      "-1\n",
      "46987\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[WARNING] Could not find [567, 573): 'DENVER'\n",
      "[WARNING] Invalid span [?, 27): 'ZYWIEC'\n",
      "[WARNING] Could not find [1398, 1405): 'Austria'\n",
      "[WARNING] Could not find [21, 37): 'SKIING-WORLD CUP'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The correct_span did not match lines. train, 0\n",
      "17719\n",
      "The correct_span did not match lines. train, 1\n",
      "-2\n",
      "The correct_span did not match lines. train, 2\n",
      "-2\n",
      "37914\n",
      "37926\n",
      "37933\n",
      "38844\n",
      "65636\n",
      "75410\n",
      "75410\n",
      "75410\n",
      "75410\n",
      "95553\n",
      "139024\n",
      "139024\n",
      "146605\n",
      "164709\n",
      "213462\n",
      "213462\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[WARNING] Could not find [51, 59): 'Interfax'\n",
      "[WARNING] Could not find [23, 27): 'News'\n"
     ]
    }
   ],
   "source": [
    "splits = ['dev', 'test', 'train']\n",
    "\n",
    "for split in splits:    \n",
    "    # Read the raw corpus file lines\n",
    "    f = open(files[split])\n",
    "    lines = f.readlines()\n",
    "    \n",
    "    # Create a dataframe for the corpus file and process our corrections csv\n",
    "    dataset = Dataset(files[split])\n",
    "    current_df = correction_df[split]\n",
    "    \n",
    "    current_df[\"line_no\"] = 0; \n",
    "    current_df[\"correct_line\"] = \"\"; \n",
    "    current_df[\"fold\"] =  split;\n",
    "\n",
    "    \n",
    "    \n",
    "    \n",
    "    for i, row in current_df.iterrows():\n",
    "        if split == 'test' and i >= 59:\n",
    "            continue\n",
    "        try:\n",
    "            candidate_lines = dataset.find(row[\"corpus_span\"], int(row[\"doc_offset\"]))\n",
    "        except:\n",
    "            candidate_lines = dataset.find(row[\"correct_span\"], int(row[\"doc_offset\"]))\n",
    "            candidate_lines = (candidate_lines[0]-1, candidate_lines[1]+1)\n",
    "            print(\"The correct_span did not match lines. {}, {}\".format(split, i))\n",
    "        current_df.at[i,\"line_no\"] = candidate_lines[0]\n",
    "        print(candidate_lines[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fold</th>\n",
       "      <th>line_no</th>\n",
       "      <th>doc_offset</th>\n",
       "      <th>corpus_span</th>\n",
       "      <th>correct_span</th>\n",
       "      <th>correct_line</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>test</td>\n",
       "      <td>1131</td>\n",
       "      <td>3.0</td>\n",
       "      <td>[21, 37): 'SKIING-WORLD CUP'</td>\n",
       "      <td>[28, 37): 'WORLD CUP'</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>test</td>\n",
       "      <td>1131</td>\n",
       "      <td>3.0</td>\n",
       "      <td>[21, 37): 'SKIING-WORLD CUP'</td>\n",
       "      <td>[28,37)'WORLD CUP'</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>test</td>\n",
       "      <td>5174</td>\n",
       "      <td>22.0</td>\n",
       "      <td>[19, 23): 'ARAB'</td>\n",
       "      <td>[19, 35): 'ARAB CONTRACTORS'</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>test</td>\n",
       "      <td>6545</td>\n",
       "      <td>27.0</td>\n",
       "      <td>[565, 573): 'X-DENVER'</td>\n",
       "      <td>[567, 573): 'DENVER'</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>test</td>\n",
       "      <td>-2</td>\n",
       "      <td>27.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[567, 573): 'DENVER'</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>train</td>\n",
       "      <td>139024</td>\n",
       "      <td>593.0</td>\n",
       "      <td>[45, 57): 'France-Juppe'</td>\n",
       "      <td>[52, 57): 'Juppe'</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>train</td>\n",
       "      <td>146605</td>\n",
       "      <td>626.0</td>\n",
       "      <td>[42, 59): 'disarmament-China'</td>\n",
       "      <td>[42, 59): 'disarmament-China'</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>train</td>\n",
       "      <td>164709</td>\n",
       "      <td>701.0</td>\n",
       "      <td>[17, 30): 'union-England'</td>\n",
       "      <td>[23, 30): 'England'</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>train</td>\n",
       "      <td>213462</td>\n",
       "      <td>918.0</td>\n",
       "      <td>[11, 24): 'INTERVIEW-T&amp;N'</td>\n",
       "      <td>[11, 24): 'INTERVIEW-T&amp;N'</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>train</td>\n",
       "      <td>213462</td>\n",
       "      <td>918.0</td>\n",
       "      <td>[11, 24): 'INTERVIEW-T&amp;N'</td>\n",
       "      <td>[21, 24): 'T&amp;N'</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>77 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     fold  line_no  doc_offset                    corpus_span  \\\n",
       "0    test     1131         3.0   [21, 37): 'SKIING-WORLD CUP'   \n",
       "1    test     1131         3.0   [21, 37): 'SKIING-WORLD CUP'   \n",
       "2    test     5174        22.0               [19, 23): 'ARAB'   \n",
       "3    test     6545        27.0         [565, 573): 'X-DENVER'   \n",
       "4    test       -2        27.0                            NaN   \n",
       "..    ...      ...         ...                            ...   \n",
       "14  train   139024       593.0       [45, 57): 'France-Juppe'   \n",
       "15  train   146605       626.0  [42, 59): 'disarmament-China'   \n",
       "16  train   164709       701.0      [17, 30): 'union-England'   \n",
       "17  train   213462       918.0      [11, 24): 'INTERVIEW-T&N'   \n",
       "18  train   213462       918.0      [11, 24): 'INTERVIEW-T&N'   \n",
       "\n",
       "                     correct_span correct_line  \n",
       "0           [28, 37): 'WORLD CUP'               \n",
       "1              [28,37)'WORLD CUP'               \n",
       "2    [19, 35): 'ARAB CONTRACTORS'               \n",
       "3            [567, 573): 'DENVER'               \n",
       "4            [567, 573): 'DENVER'               \n",
       "..                            ...          ...  \n",
       "14              [52, 57): 'Juppe'               \n",
       "15  [42, 59): 'disarmament-China'               \n",
       "16            [23, 30): 'England'               \n",
       "17      [11, 24): 'INTERVIEW-T&N'               \n",
       "18                [21, 24): 'T&N'               \n",
       "\n",
       "[77 rows x 6 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full_df = pd.DataFrame()\n",
    "full_df = test_df.append(dev_df).append(train_df)\n",
    "full_df = full_df[['fold','line_no', 'doc_offset', 'corpus_span', 'correct_span', 'correct_line']];\n",
    "full_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"../corrected_labels/token_edits.csv\",'w')as file:\n",
    "    full_df.to_csv(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
