{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import glob\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import text_extensions_for_pandas as tp\n",
    "from download_and_correct_corpus import Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "files = {\n",
    "    'csv_files' : [\"../corrected_labels/all_conll_corrections_combined.csv\"],\n",
    "    'dev'       : \"../original_corpus/eng.testa\",\n",
    "    'test'      : \"../original_corpus/eng.testb\",\n",
    "    'train'     : \"../original_corpus/eng.train\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = ['doc_offset', 'corpus_span', 'correct_span']\n",
    "\n",
    "test_df = pd.DataFrame(columns = columns)\n",
    "dev_df = pd.DataFrame(columns = columns)\n",
    "train_df = pd.DataFrame(columns = columns)\n",
    "\n",
    "for f in files['csv_files']:\n",
    "    current_df = pd.read_csv(os.path.abspath(f))\n",
    "    test_df = test_df.append(current_df[(current_df[\"error_type\"]==\"Sentence\") & (current_df[\"fold\"]==\"test\")][columns], ignore_index=True)\n",
    "    dev_df = dev_df.append(current_df[(current_df[\"error_type\"]==\"Sentence\") & (current_df[\"fold\"]==\"dev\")][columns], ignore_index=True)\n",
    "    train_df = train_df.append(current_df[(current_df[\"error_type\"]==\"Sentence\") & (current_df[\"fold\"]==\"train\")][columns], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df.to_csv(\"../corrected_labels/sentence_corection_test.csv\")\n",
    "dev_df.to_csv(\"../corrected_labels/sentence_corection_dev.csv\")\n",
    "train_df.to_csv(\"../corrected_labels/sentence_corection_train.csv\")\n",
    "correction_df = {\n",
    "    'dev'  : dev_df,\n",
    "    'test' : test_df,\n",
    "    'train': train_df\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nothing to append here! Check test, 20 again\n",
      "Nothing to append here! Check test, 30 again\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[WARNING] Could not find [76, 107): 'National Basketball Association': No span begins with 76\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nothing to append here! Check train, 37 again\n",
      "Nothing to append here! Check train, 38 again\n",
      "Nothing to append here! Check train, 39 again\n",
      "Nothing to append here! Check train, 76 again\n",
      "Nothing to append here! Check train, 77 again\n",
      "Nothing to append here! Check train, 78 again\n",
      "Nothing to append here! Check train, 107 again\n",
      "Nothing to append here! Check train, 108 again\n",
      "Nothing to append here! Check train, 111 again\n"
     ]
    }
   ],
   "source": [
    "splits = ['dev', 'test', 'train']\n",
    "lines_to_delete = {\n",
    "    'dev'  : [],\n",
    "    'test' : [],\n",
    "    'train': []\n",
    "}\n",
    "\n",
    "for split in splits:    \n",
    "    # Read the raw corpus file lines\n",
    "    f = open(files[split])\n",
    "    lines = f.readlines()\n",
    "    \n",
    "    # Create a dataframe for the corpus file and process our corrections csv\n",
    "    dataset = Dataset(files[split])\n",
    "    current_df = correction_df[split]\n",
    "    for i, row in current_df.iterrows():\n",
    "        if split == 'test' and i >= 59:\n",
    "            continue\n",
    "        try:\n",
    "            candidate_lines = dataset.find(row[\"correct_span\"], int(row[\"doc_offset\"]))\n",
    "        except:\n",
    "            candidate_lines = dataset.find(row[\"corpus_span\"], int(row[\"doc_offset\"]))\n",
    "            candidate_lines = (candidate_lines[0]-1, candidate_lines[1]+1)\n",
    "            print(\"The correct_span did not match lines, using corpus span instead at {}, {}\".format(split, i))\n",
    "        appended = 0\n",
    "        for c in range(candidate_lines[0], candidate_lines[1]+1):\n",
    "            if lines[c] == \"\\n\":\n",
    "                lines_to_delete[split].append(c)\n",
    "                appended += 1\n",
    "        if appended == 0:\n",
    "            print(\"Nothing to append here! Check {}, {} again\".format(split, i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "for l in lines_to_delete:\n",
    "    lines_to_delete[l] = list(dict.fromkeys(lines_to_delete[l]))\n",
    "    lines_to_delete[l].sort(reverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'dev': [42643,\n",
      "         38843,\n",
      "         30692,\n",
      "         30675,\n",
      "         30645,\n",
      "         7869,\n",
      "         7856,\n",
      "         7843,\n",
      "         7430,\n",
      "         6727,\n",
      "         6672,\n",
      "         5414,\n",
      "         4452,\n",
      "         4426,\n",
      "         3216,\n",
      "         2783],\n",
      " 'test': [49123,\n",
      "          48763,\n",
      "          48676,\n",
      "          48357,\n",
      "          48257,\n",
      "          46910,\n",
      "          46858,\n",
      "          46839,\n",
      "          46144,\n",
      "          43778,\n",
      "          43726,\n",
      "          43649,\n",
      "          42051,\n",
      "          8658,\n",
      "          8636,\n",
      "          8628,\n",
      "          8612,\n",
      "          8597,\n",
      "          7560,\n",
      "          6829,\n",
      "          6104,\n",
      "          5640,\n",
      "          5267,\n",
      "          5047,\n",
      "          3155,\n",
      "          1892],\n",
      " 'train': [219502,\n",
      "           219329,\n",
      "           217807,\n",
      "           216156,\n",
      "           192381,\n",
      "           188610,\n",
      "           188128,\n",
      "           188098,\n",
      "           188070,\n",
      "           188055,\n",
      "           187979,\n",
      "           187959,\n",
      "           179109,\n",
      "           179107,\n",
      "           179104,\n",
      "           173869,\n",
      "           161214,\n",
      "           161023,\n",
      "           159412,\n",
      "           159351,\n",
      "           158735,\n",
      "           158689,\n",
      "           156226,\n",
      "           154243,\n",
      "           150308,\n",
      "           150294,\n",
      "           150231,\n",
      "           138533,\n",
      "           123300,\n",
      "           123287,\n",
      "           122102,\n",
      "           121120,\n",
      "           102353,\n",
      "           93933,\n",
      "           93899,\n",
      "           93160,\n",
      "           91425,\n",
      "           80898,\n",
      "           77860,\n",
      "           76356,\n",
      "           76178,\n",
      "           74427,\n",
      "           73208,\n",
      "           73188,\n",
      "           71288,\n",
      "           70208,\n",
      "           70129,\n",
      "           70110,\n",
      "           70063,\n",
      "           70043,\n",
      "           70024,\n",
      "           69329,\n",
      "           69299,\n",
      "           69065,\n",
      "           69027,\n",
      "           68994,\n",
      "           58457,\n",
      "           55816,\n",
      "           35223,\n",
      "           35176,\n",
      "           35134,\n",
      "           32889,\n",
      "           32235,\n",
      "           32027,\n",
      "           30975,\n",
      "           30773,\n",
      "           12691,\n",
      "           12623,\n",
      "           12609,\n",
      "           12582,\n",
      "           12500,\n",
      "           12487,\n",
      "           10824,\n",
      "           9489,\n",
      "           9200,\n",
      "           8594,\n",
      "           8514,\n",
      "           8441,\n",
      "           7926,\n",
      "           7622,\n",
      "           7243,\n",
      "           5833,\n",
      "           5803,\n",
      "           5727]}\n"
     ]
    }
   ],
   "source": [
    "import pprint\n",
    "pprint.pprint(lines_to_delete)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "json = json.dumps(lines_to_delete, indent=4, sort_keys=True)\n",
    "f = open(\"../corrected_labels/sentence_corrections.json\",\"w\")\n",
    "f.write(json)\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
